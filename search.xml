<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Lookign for the Devil in the Details:Learning Trilinear Attention Sampling Network for Fine-grained Image Recongnition</title>
      <link href="/2019/09/06/Lookign-for-the-Devil-in-the-Details-Learning-Trilinear-Attention-Sampling-Network-for-Fine-grained-Image-Recongnition/"/>
      <url>/2019/09/06/Lookign-for-the-Devil-in-the-Details-Learning-Trilinear-Attention-Sampling-Network-for-Fine-grained-Image-Recongnition/</url>
      
        <content type="html"><![CDATA[<p>Lookign-for-the-Devil-in-the-Details-Learning-Trilinear-Attention-Sampling-Network-for-Fine-grained-Image-Recongnition 是2019年CVPR一篇关于细粒度的文章<br><a href="https://arxiv.org/pdf/1903.06150.pdf" target="_blank" rel="noopener">文章传送门</a></p><h2 id="一-文章简介"><a href="#一-文章简介" class="headerlink" title="一 文章简介"></a>一 文章简介</h2><p>文章提出了一种TASN卷积神经网络，主要要解决现有的注意力机制网络，受注意力区域数目，以及计算量限制的问题<br>   设计思路如图所示<br>   <img src="/images/Lookign/1.png" alt><br>   即通过TASN网络，对图像局部区域的特征进行“专注”的学习</p><h2 id="二-模型"><a href="#二-模型" class="headerlink" title="二 模型"></a>二 模型</h2><p><img src="/images/Lookign/2.png" alt>)</p><p>模型的主体结构主要由三部分构成：<br>  1.trilinear attention:通过通道间的联系，构建通道级别的attention图<br>  2.channel level sampling:对不同的通道区域进行采样<br>  3.feature distiller：通过知识蒸馏以及参数共享，实现对局部特征的融合</p><p>将图片输入卷积网络得到卷积特征输入TASN得到通道的注意图，上部分对整个注意力图做average pooling后与原图像经采样后共同输入待训练的卷积神经网络，下部分按照文中的channel level sampling对单个通道注意力图进行采样，采样出单张后与原图像经过采样后输入待训练的卷积神经网络，上下两部分的卷积网络参数共享，上半部分作为训练的结构框架，下半部分通过featuredistiller的方式对卷积神经网络的局部细节进行补充。</p><h2 id="三-方法流程"><a href="#三-方法流程" class="headerlink" title="三 方法流程"></a>三 方法流程</h2><h3 id="3-1-trilinear-attention"><a href="#3-1-trilinear-attention" class="headerlink" title="3.1 trilinear attention"></a>3.1 trilinear attention</h3><p>trilinear attention的主要结构如图所示<br><img src="/images/Lookign/3.png" alt>)</p><p>之前提到过，不同卷积层对特征的不同区域的敏感性是不同的，也就是说，不同卷积层我们可以认为是可以生成不同感知区域的attention 文章根据feature channel的空间关系对通道特征进行整合，将特征图转化为前向传播的注意力图，这种注意力图的生成方式与平常接触的CAM图还是有差别的，<br>CAM是根据分类loss反向传播得到的特征图，trilinear attention这种特征图生成方式更类似与前向生成的特征图。<br>文章提出的三线性特征为：<br><img src="/images/Lookign/4.png" alt><br>为了提高三线性注意力的有效性，文章提出了一种非线性形式的三线性注意力<br><img src="/images/Lookign/5.png" alt><br>其中N为softmax函数，第一个softmax目的是保持通道级信息在同一尺度上（0-1），第二个softmax在每个通道级特征上进行非线性，目的是更好的突出attention区域。<br>文章还提到，为了获取位置更加准确的feature map，文章通过改变卷积核移除了resnet网络的两个下采样图，以及增加扩张卷积从而增加卷积网路网络的感受野。</p><h3 id="3-2-channel-level-sampling"><a href="#3-2-channel-level-sampling" class="headerlink" title="3.2 channel level sampling"></a>3.2 channel level sampling</h3><p>文章将原图像与三线注意力图作为输入，分别生成保留结构信息以及局部细节信息的feature，与直接输入原始图像相比，保留的结构去除了没有细粒度细节的区域，因此能够更好的表示辨识部分，细节信息的图像更着重与单个部分，可以保留更具有细粒度细节信息。<br><img src="/images/Lookign/6.png" alt><br>其中，I是输入原图像，M是3.1中生成的attention map，S表示非线性采样，A代表在通道尺度上的average pooling（代表结构信息），R表示从输入attention map随机选取通道的单个feature（局部细节信息）通过不断的训练，每一个channel 都有可能被选到。<br>这部分比较重要的部分是采样函数S的定义<br><img src="/images/Lookign/7.png" alt></p><p>文章将注意力图是做概率权重函数，也就是说具有较大注意力值得区域，有更大的概率被采样到。具体过程为：分别对attention图进行x轴和y轴的最大特征值得映射，生成（b1）和（b2），文章说采用最大值有比较强的代表性以及鲁棒性，对其在x和y轴进行积分，生成（c1）和（c2）曲线，曲线的斜率也就代表着这点特征值得大小，然后对其进行一个反函数的操作<br><img src="/images/Lookign/10.png" alt><br>经过反函数后，可以看到图中x,y轴表示图像，关于y=x轴对称了，这样的话，如果对x轴进行均匀采样的话，在原图像，就能采样到更为密集的点，原因就在于，原本那一点的斜率比较大，经过反函数后斜率就变小了，也就是说，均匀采样的话可以在原本密集的区域获取更多的采样点。这也就是为什么（c1）(c2)会一那样的图形进行表示。采样过后生成图e 可以知道，采样出的图像在特征密集点区域更加突出。</p><h3 id="3-3-feature-distiller"><a href="#3-3-feature-distiller" class="headerlink" title="3.3 feature distiller"></a>3.3 feature distiller</h3><p>通过知识蒸馏的方式，将网络提取的细节信息，以及结构信息作为Part-Net以及Master-Net网络的输入，如模型图所示，将从Part-Net学到的图像语义细节信息，传输给Master-Net。将获取的结构信息Is 与 Id分别输入参数共享的卷积神经网络中，经过不同的全连接层+softmax获得分别的分类结果Zs和Zd，如下图所示：<br><img src="/images/Lookign/11.png" alt><br>其中T为温度系数，是一个超参数，在分类任务中，绝大多数情况值为1，也就是我们最常见的softmax形式，但是在feature distiller中，T的值不是1 目的是为了让分类结果产生软概率分布。<br>这样就可以得到Master-Net中的软目标交叉熵。<br><img src="/images/Lookign/12.png" alt><br>其中qs和qd分别代表经过Zs和Zd经过softmax后的预测概率值<br>最后，Master-Net的目标函数为：<br><img src="/images/Lookign/13.png" alt><br>软目标交叉熵的目的在于将网络获取的细节特征传送给Master-Net，在训练过程中，每次从训练的样本中随机选择一个通道信息作为输入，产生不同的细节信息，经过大量训练后，每一个细节都会被补充到结构信息当中，完成了文章最初的设计想法。</p>]]></content>
      
      
      <categories>
          
          <category> 论文分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文分享 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 细粒度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MACNN-Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition</title>
      <link href="/2019/09/05/MACNN-Learning-Multi-Attention-Convolutional-Neural-Network-for-Fine-Grained-Image-Recognition/"/>
      <url>/2019/09/05/MACNN-Learning-Multi-Attention-Convolutional-Neural-Network-for-Fine-Grained-Image-Recognition/</url>
      
        <content type="html"><![CDATA[<p>Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition 是2017年CVPR一篇关于细粒度的文章<br><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf" target="_blank" rel="noopener">文章传送门</a></p><h2 id="一-文章简介"><a href="#一-文章简介" class="headerlink" title="一 文章简介"></a>一 文章简介</h2><p>文章提出了一种采用弱监督学习的多注意力的卷积神经网络，主要要解决以下两个问题：<br>                 1.当前的细粒度分类方法主要依赖于具有区分度的局部信息或者基于局部的精准信息，少有将二者联系起来的模型。<br>                 2.基于局部信息的模型，通常需要手工标注注意力区域，这需要耗费大量人力。</p><h2 id="二-文章的亮点"><a href="#二-文章的亮点" class="headerlink" title="二 文章的亮点"></a>二 文章的亮点</h2><p>1.由于卷积层不同通道对图像的感知敏感性是不同的，文章利用这一点，在通道特征的利用上下了一定功夫，得到不同通道级别的注意力区域<br>2.文章针对生成的注意力区域设置了channel group loss，目的是为了让生成的不同通道级别注意力区域更加有信息性以及代表性</p><h2 id="三-模型"><a href="#三-模型" class="headerlink" title="三 模型"></a>三 模型</h2><p><img src="/images/MACNN/base.png" alt="3.1"></p><p>如图3.1所示，文章认为不同的鸟类，在相同部分，如翅膀，嘴尖，爪子上有的微妙的视觉差异，文章主要利用这一点，分别选取鸟类中具有判别性的区域，输入其设计的多注意力网络，实现对鸟类的判别</p><p><img src="/images/MACNN/basemodel.png" alt="3.2"></p><p>网络的整体结构如图3.2所示，输入一张图片到卷积神经网络，由于卷积层的不同通道对事物的感知能力是不同的，有的卷积层对翅膀可能更敏感，有的可能对嘴尖更敏感（以鸟为例），所以有图3.2（c）中对同一卷积层的通道展开，有不同灰色感知区域的差别，文章通过聚类算法对相同感知区域的卷积通道进行聚类，假设聚类中心为4（图3.2e中的四幅图），对处于同一聚类结果的不同通道卷积层进行通道级求和，就得到了图3.2e的部分，再对其进行归一化处理，sigmoid函数，产生四个不同区域的空间注意力mask，mask主要是用于定位局部特征区域，mask与卷积层的特征进行点乘，便得到了不同区域细化的卷积特征，分别进行softmax分类。</p><h2 id="四-方法流程"><a href="#四-方法流程" class="headerlink" title="四 方法流程"></a>四 方法流程</h2><h3 id="4-1-通道级特征选取"><a href="#4-1-通道级特征选取" class="headerlink" title="4.1 通道级特征选取"></a>4.1 通道级特征选取</h3><p>个人认为是文章最具有创新性的部分</p><p>channel grouping 预训练</p><p>直接用初始化参数训练，容易造成这部分陷入局部最优解，这就需要对其进行提前的预训练处理</p><p>预训练过程中，feature map 每一个channel都会产生信息突出点，也就是被激活的区域，我们可以将激活值最高的区域的（）坐标作为这个channel代表特征，用于参与聚类。<br><img src="/images/MACNN/first.png" alt="4.1"><br>将图4.1的channel 代表特征进行聚类，聚成N簇，在分别对其每一簇进行编码<br><img src="/images/MACNN/second.png" alt="4.2"><br>若向量的channel 属于当前簇，则将其设为1，否者设为0，也就是说，假设只有A,B两簇，A簇为【1,0,0,0,1】，那么B簇的编码必为【0,1,1,1,0],即编码后的N簇是互斥的。但是这样的处理方式存在一个问题，那就是无法在同一网络进行端对端的训练。<br>所以文章采用了用全连接层替代强行0.1编码的方式，改用N组全连接层，每个全连接层收网络的特征，生成一个权重向量di<br><img src="/images/MACNN/third.png" alt="4.3"><br>为了让获得的di更加准确，文章需要对全连接层的参数进行预训练，即图4.3的值尽可能的趋近于图4.2的值。经过这样的处理后，我们得到了N个部分的卷积特征掩码，通过图4.4，即feature map 与mask点乘后，通道求和。在经过sigmoid进行归一化处理得到 probabilities map。<br><img src="/images/MACNN/forth.png" alt="4.4"><br>综合起来得到图4.5，channe group 特征的获取方式</p><p><img src="/images/MACNN/fifth.png" alt="4.5"><br>其中，W为全脸层参数，X为输入卷积特征，M为得到的channel attention mask</p><h3 id="4-2-损失函数"><a href="#4-2-损失函数" class="headerlink" title="4.2 损失函数"></a>4.2 损失函数</h3><p><img src="/images/MACNN/sixth.png" alt="4.6"><br>整体损失函数如图4.6所示共有以下两部分构成</p><h4 id="分类损失"><a href="#分类损失" class="headerlink" title="分类损失"></a>分类损失</h4><p>常见的交叉熵分类损失，N个part损失共同求和优化</p><h4 id="channel-group-part-损失"><a href="#channel-group-part-损失" class="headerlink" title="channel group part 损失"></a>channel group part 损失</h4><p>为了使 channel group part 同一part 距离更近，不同part距离更远，文章提出了DIS 和 DIV 两种损失函数如图4.8,4.9所示</p><p><img src="/images/MACNN/eighth.png" alt="4.8"><br><img src="/images/MACNN/ninth.png" alt="4.9"></p><p> 这部分整体损失函数为图4.10</p><p><img src="/images/MACNN/seventh.png" alt="4.10"></p><h3 id="训练方式"><a href="#训练方式" class="headerlink" title="训练方式"></a>训练方式</h3><p>文章采用了交替训练的方式，即分类部分与channel group 部分相互强化训练的方式，固定一部分，训练另一部分，直到二者损失均平稳，认为训练完成</p><h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五 总结"></a>五 总结</h2><p>文章在channel group 那部分设置十分巧妙，通过N组全连接层去替代1.0编码 以及在文章区域信息的把握上值得学习与借鉴。</p>]]></content>
      
      
      <categories>
          
          <category> 论文分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文分享 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 细粒度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python将批量图片以txt文件存储，并读取</title>
      <link href="/2019/08/28/python%E5%B0%86%E6%89%B9%E9%87%8F%E5%9B%BE%E7%89%87%E4%BB%A5txt%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%EF%BC%8C%E5%B9%B6%E8%AF%BB%E5%8F%96/"/>
      <url>/2019/08/28/python%E5%B0%86%E6%89%B9%E9%87%8F%E5%9B%BE%E7%89%87%E4%BB%A5txt%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%EF%BC%8C%E5%B9%B6%E8%AF%BB%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<h2 id="将图片存储为txt的原因"><a href="#将图片存储为txt的原因" class="headerlink" title="将图片存储为txt的原因"></a>将图片存储为txt的原因</h2><p>在将图片数据输入卷积神经网络时，如果通过np.load进行输入，常常会出现内存爆炸的问题，为节约内存，将图片按照txt文件读取，是一种非常好的读取方式，当然啊，如今ternsorflow出的API也相当不错。技多不压身嘛！</p><h2 id="将图片存储为txt文件代码"><a href="#将图片存储为txt文件代码" class="headerlink" title="将图片存储为txt文件代码"></a>将图片存储为txt文件代码</h2><pre><code class="javascript"> &#39;&#39;&#39; 本代码以UC数据集为例子，UC数据集共包含21类，每一类图片包含100张图片 其中class_label_dict为UC数据集label， &#39;&#39;&#39;import numpy as npimport osclass_label_dict = {&#39;agricultural&#39;: 0,                    &quot;airplane&quot;: 1,                    &quot;baseballdiamond&quot;: 2,                    &quot;beach&quot;: 3,                    &quot;buildings&quot;: 4,                    &quot;chaparral&quot;: 5,                    &quot;denseresidential&quot;: 6,                    &quot;forest&quot;: 7,                    &quot;freeway&quot;: 8,                    &quot;golfcourse&quot;: 9,                    &quot;harbor&quot;: 10,                    &quot;intersection&quot;: 11,                    &quot;mediumresidential&quot;: 12,                    &quot;mobilehomepark&quot;: 13,                    &quot;overpass&quot;: 14,                    &quot;parkinglot&quot;: 15,                    &quot;river&quot;: 16,                    &quot;runway&quot;: 17,                    &quot;sparseresidential&quot;: 18,                    &quot;storagetanks&quot;: 19,                    &quot;tenniscourt&quot;: 20                    }file_path = &quot;G:/UC&quot;                                  #此处为文件存放位置path_list = os.listdir(file_path)                 #会历遍文件夹内的文件并返回一个列表path_name=[]for i in path_list:    path_name.append(file_path+&quot;/&quot;+i+&quot; &quot;+str(class_label_dict[i[:-6]]))path_name.sort()train_path = []test_path = []trains_idx = []tests_idx = []for i in range(21):    start = i * 100    end = (i + 1) * 100    idx = np.arange(start, end)    np.random.shuffle(idx)    train_idx = idx[0:80]    test_idx = idx[80:]    trains_idx.extend(train_idx)    tests_idx.extend(test_idx)path_name = np.array(path_name)train_path = path_name[trains_idx]test_path = path_name[tests_idx]for file_name in path_name:    # &quot;a&quot;表示以不覆盖的形式写入到文件中,当前文件夹如果没有&quot;save.txt&quot;会自动创建    with open(&quot;data.txt&quot;, &quot;a&quot;) as f:        f.write(file_name + &quot;\n&quot;)    f.close()for file_name in train_path:    # &quot;a&quot;表示以不覆盖的形式写入到文件中,当前文件夹如果没有&quot;save.txt&quot;会自动创建    with open(&quot;train.txt&quot;, &quot;a&quot;) as f:        f.write(file_name + &quot;\n&quot;)    f.close()for file_name in test_path:    # &quot;a&quot;表示以不覆盖的形式写入到文件中,当前文件夹如果没有&quot;save.txt&quot;会自动创建    with open(&quot;test.txt&quot;, &quot;a&quot;) as f:        f.write(file_name + &quot;\n&quot;)    f.close()</code></pre><p>输出txt文件的格式为 文件位置+文件名+label形式 ，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190707221102570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="txt结果图"></p><h2 id="将txt文件进行批量读取"><a href="#将txt文件进行批量读取" class="headerlink" title="将txt文件进行批量读取"></a>将txt文件进行批量读取</h2><pre><code class="javascript">def read_txt():    train_filename = []    train_filelabel = []    with open(&#39;/home/admin324/PycharmProjects/qiushuo/A_GS/data/train.txt&#39;, &#39;r&#39;) as f:        x = f.readlines()        for name in x:            train_filename.append(name.strip().split()[0])            train_filelabel.append(int(name.strip().split()[1]))    train_filename = np.array(train_filename)    train_filelabel = np.array(train_filelabel)    test_filename = []    test_filelabel = []    with open(&#39;/home/admin324/PycharmProjects/qiushuo/A_GS/data/test.txt&#39;, &#39;r&#39;) as f:        x = f.readlines()        for name in x:            test_filename.append(name.strip().split()[0])            test_filelabel.append(int(name.strip().split()[1]))    test_filename = np.array(test_filename)    test_filelabel = np.array(test_filelabel)    return train_filename, train_filelabel, test_filename, test_filelabeldef read_data(path):    data = []    for i in range(path.shape[0]):        temp = cv2.imread(path[i])        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)        temp = cv2.resize(temp, dsize=(224, 224))        data.append(temp / 255.)    data = np.array(data)    return data</code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 深度学习编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu+CUDA10.0+cuDNN7.5.0+anaconda+tensorflow—gpu安装教程</title>
      <link href="/2019/08/20/ubuntu%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8+tensorflow%E2%80%94gpu%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>/2019/08/20/ubuntu%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8+tensorflow%E2%80%94gpu%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>Ubuntu+CUDA10.0+cuDNN7.5.0+anaconda+tensorflow—gpu安装教程</p><p>配置：ubuntu19.04<br>显卡：GEFORCE 840M  </p><h1 id="一-Ubuntu19-04安装"><a href="#一-Ubuntu19-04安装" class="headerlink" title="一  Ubuntu19.04安装"></a>一  Ubuntu19.04安装</h1><p>网络上有很多文章，首先博主是根据B站UP主上的视频一步一步走下来的，有一个视频是讲双系统的，楼主垃圾笔记本一台装了ubuntu和win10双系统，有需要的同学可以上B站搜一下ubuntu安装这里就不放链接了。</p><h2 id="二-一定要看好自己笔记本支持的下载的CUDA和cuDNN版本搞清楚！"><a href="#二-一定要看好自己笔记本支持的下载的CUDA和cuDNN版本搞清楚！" class="headerlink" title="二   一定要看好自己笔记本支持的下载的CUDA和cuDNN版本搞清楚！"></a>二   一定要看好自己笔记本支持的下载的CUDA和cuDNN版本搞清楚！</h2><p>登录网站   <a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-gpus</a><br>首先看看自己的显卡支不支持tensorflow—GPU</p><p><img src="https://img-blog.csdnimg.cn/2019050413481569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="支持加速的显卡"><br>博主的老爷车GEFORCE 840M 竟然在里面！难以置信</p><h2 id="三-安装显卡驱动"><a href="#三-安装显卡驱动" class="headerlink" title="三  安装显卡驱动"></a>三  安装显卡驱动</h2><p>楼主小白一枚 实在不明白又是禁用源驱动 又是一堆的神奇操作 选用了所有博主最不推荐的</p><pre><code class="javascript">sudo ubuntu-drivers autoinstall </code></pre><p>  博主选了一堆yes 由于之前安装过了 这里就不放截图了。安装完后印象里会安装好几个显卡驱动，通过ubuntu里面的软件与更新<img src="https://img-blog.csdnimg.cn/20190504135458560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="ubuntu驱动安装列表"><br>里面的附加驱动使用了418这个版本。安装完显卡驱动后重新启动下电脑，在终端运行</p><pre><code class="javascript">nvidia-smi</code></pre><p><img src="https://img-blog.csdnimg.cn/20190504135844182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="验证显卡驱动是否安装成功"><br>说明显卡驱动安装成功，万里长城第一步啊。接下来就是安装CUDA和cuDNN</p><h2 id="四-安装CUDA"><a href="#四-安装CUDA" class="headerlink" title="四 安装CUDA"></a>四 安装CUDA</h2><p><img src="https://img-blog.csdnimg.cn/20190504140145732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="CUDA与显卡版本号关系"><br>这个是显卡驱动对应的CUDA版本我们安装的显卡驱动版本是418.56&gt;418.39 所以博主选用的CUDA是10.0版本。<br>然后同学们 去<br><a href="https://developer.nvidia.com/cuda-release-candidate-download" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-release-candidate-download</a><br>根据自己的系统下载CUDA 这里就不放图了 但是要记住 下载runfile(local)文件<br>下载完后找到下载CUDA文件的位置 右键打开终端 输入：<br>在安装CUDA的过程中会提示，CUDA10.0 设备不可用 在安装那一步 -overrid  我百度查到的结果是编译器不兼容导致的。</p><pre><code class="javascript">sudo chmod +x cuda_10.0.130_410.48_linux.runsudo ./cuda_10.0.130_410.48_linux.run -overrid</code></pre><p>注意上面的数字根据自己下载的版本号更改<br>在安装CUDA的时候 注意不要安装CUDA所带的驱动 由于我们之前安装了显卡驱动了 所以不需要重复安装</p><p>然后就是配置环境 输入终端命令</p><pre><code class="javascript">sudo gedit ~/.bashrc</code></pre><p>进入编辑模式将下面两条命令加入文档最后面：下面的序列号也需要根据自己的CUDA版本号更改</p><pre><code class="javascript">export PATH=/usr/local/cuda-10.0/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH</code></pre><p>加入后在终端输入，从而使得环境生效</p><pre><code class="javascript">source ~/.bashrc</code></pre><p>在终端输入，即可得到我们的CUDA信息 10.0.130</p><pre><code class="javascript">nvcc -V</code></pre><p>现实如下 可见我们安装的CUDA版本为10.0.130</p><pre><code class="javascript">maqiushuo@maqiushuo-Aspire-E5-572G:~$ nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2018 NVIDIA CorporationBuilt on Sat_Aug_25_21:08:01_CDT_2018Cuda compilation tools, release 10.0, V10.0.130</code></pre><p>验证<br>打开终端输入</p><pre><code class="javascript">cd /usr/local/cuda/samples/1_Utilities/deviceQuery sudo make./deviceQuery</code></pre><p>得到以下结果，及说名CUDA安装成功<br><img src="https://img-blog.csdnimg.cn/20190521211742747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="验证CUDA安装是否成功"></p><h2 id="五-安装cuDNN"><a href="#五-安装cuDNN" class="headerlink" title="五 安装cuDNN"></a>五 安装cuDNN</h2><p>打开网站<br><a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a></p><p>下载自己需要的cuDNN</p><p><img src="https://img-blog.csdnimg.cn/20190504145205682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="cuDNN版本号"><br>我下载的版本为 10.0    下的   cuDNN library for linux<br>下载完成后输入以下命令<br>首先进入你下载文件的文件夹<br>然后解压文件运行以下代码，注意 解压的文件是你下载的文件。。我这里只是提供个例子，当时下载的到底是什么名字我也忘了，所以下面代码的第一行是解压你下载的安装包.要根据你自己的cudnn版本号更改的</p><pre><code class="javascript">tar -xzvf cudnn-10.0-linux-x64-v7.5.0.56.tgzsudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</code></pre><p>到这里cuDNN也已经配置完成</p><h2 id="安装anaconda-以及tensorflow-gpu"><a href="#安装anaconda-以及tensorflow-gpu" class="headerlink" title="安装anaconda 以及tensorflow-gpu"></a>安装anaconda 以及tensorflow-gpu</h2><p>1.安装anaconda</p><pre><code class="javascript">bash Anaconda3-5.2.0-Linux-x86_64.sh</code></pre><p>2.在anaconda当中安装 tensorflow虚拟环境这里将其命名为tensorflow</p><pre><code class="javascript">conda create -n tensorflow pip python=3.6</code></pre><p>3.激活tensorflow(之前安装的虚拟环境)</p><pre><code class="javascript">source activate tensorflow</code></pre><p>4.安装tensorflow-gpu在tensorflow当中(之前安装的虚拟环境)<br>注意不同版本的tensorflow-gpu 对应的CUDA也是不同的<br><a href="https://www.tensorflow.org/install/source" target="_blank" rel="noopener">https://www.tensorflow.org/install/source</a>  从这个网站查找对应你CUDA版本的gpu，我的电脑不能翻墙只能放一张老图<br><img src="https://img-blog.csdnimg.cn/20190504151111420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="CUDA与tensorflow-gpu对应关系"><br>从以上对应版本号上安装对应版本的tensorflow-gpu</p><pre><code class="javascript">pip install tensorflow-gpu == “你的版本”</code></pre><p> 5.验证<br><img src="https://img-blog.csdnimg.cn/20190504151306674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="验证是否成功"><br> 打开终端，激活tensorflow，输入python，输入import tensorflow as tf<br> 不报错！！！！！！就安装成功了！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！<br> 博主安装了两天，第二天凌晨4点安装成功。。哎。现在想想真的是浪费生命啊<br> 之前博主安装的是CUDA10.1，死活不兼容，后来博主百度查到，应该是anaconda公司没有更新，所以导致对CUDA10.1的不兼容。</p><p> 参考文档如下</p>]]></content>
      
      
      <categories>
          
          <category> 环境搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow-gpu </tag>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04LST+tensorflow—gpu图形工作站安装教程</title>
      <link href="/2019/08/20/Ubuntu16-04LST-tensorflow-GPU%E6%A0%87%E5%87%86%E5%B7%A5%E4%BD%9C%E7%AB%99%E5%AE%89%E8%A3%85/"/>
      <url>/2019/08/20/Ubuntu16-04LST-tensorflow-GPU%E6%A0%87%E5%87%86%E5%B7%A5%E4%BD%9C%E7%AB%99%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="一-工作站环境说明"><a href="#一-工作站环境说明" class="headerlink" title="一 工作站环境说明"></a>一 工作站环境说明</h1><p>系统：ubuntu16.04LST<br>显卡：TITAN XP<br>ps：<strong>工作站内核最好不要更新，工作站稳定第一</strong></p><h1 id="二-显卡驱动安装"><a href="#二-显卡驱动安装" class="headerlink" title="二 显卡驱动安装"></a>二 显卡驱动安装</h1><p> 我的第一篇博客介绍了CUDA 以及CUDNN 以及显卡各个版本号之间的关系。有兴趣的同学可以过去看一看，我在笔记本上安装利用ppa的形式安装的，感觉更简便一点。下面附上第一篇博客的链接<br> <a href="https://blog.csdn.net/weixin_43149427/article/details/89813192" target="_blank" rel="noopener">第一篇博客传送门</a><br>这篇讲的是工作站的安装方式</p><h2 id="1-禁用nouveau"><a href="#1-禁用nouveau" class="headerlink" title="1.禁用nouveau"></a>1.禁用nouveau</h2><pre><code class="javascript"> ctrl+alt+T  //打开终端sudo gedit /etc/modprobe.d/blacklist.conf  //进入系统启动黑名单</code></pre><p>在最后一行加入</p><pre><code class="javascript">blacklist nouveau</code></pre><p>保存，然后在终端输入，更新下之前的禁用设置</p><pre><code class="javascript">sudo update-initramfs -u更新过后会输出  update-initramfs ：Generating &#39;.......后面的忘了</code></pre><p>重新启动你的电脑，进入系统后，如果你的分辨率变小（图标变大）就说明你的nouveau成功禁用了</p><h2 id="2-安装驱动"><a href="#2-安装驱动" class="headerlink" title="2.安装驱动"></a>2.安装驱动</h2><p>博主选用的是NVIDIA-Linux-x86_64-430.09.run  关于显卡驱动的下载以及版本说明还是上一条传送门<br>找到你下载的显卡驱动的位置，进入终端首先更改驱动的运行权限，变为可执行文件</p><pre><code class="javascript">shuo chmod 777 NVIDIA-Linux-x86_64-430.09.run</code></pre><p>777当然是代表辣个男人啦。不！当然是代表三中用户的 可执行做可读可写了！-rwxrwxrwx<br>然后按下ctrl+alt+F1 进入tty1 </p><pre><code class="javascript">“输入你的用户名”“输入用户名对应密码”</code></pre><p>关停图形界面</p><pre><code class="javascript">sudo service lightdm stop</code></pre><p>找到你显卡驱动的位置，输入</p><pre><code class="javascript">sudo ./NVIDIA-Linux-x86_64-430.09.run -–no-opengl-files -–no-nouveau-check ––no-x-check</code></pre><p>–no-opengl-files 只安装驱动文件，不安装OpenGL文件。这个参数最重要<br>–no-nouveau-check 安装驱动时不检查nouveau<br>–no-x-check 安装驱动时不检查X服务<br>这三个博主是参考网上的解释。我安装的时候都加上了。因人而异，我们实验室另一台图站就不行 就只用了第一个才能装上<br>然后输入你的密码 稍等片刻即可<br>随后进入类似图形界面的驱动安装界面<br>两次左边，选择继续安装。出现安装进度条后 两次选择默认即可。安装完成后 在终端输入nvidia-smi<br>我们就可以看到类似下图的界面<br><img src="https://img-blog.csdnimg.cn/20190526101049248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="nvidia_smi效果"><br>这张图片是我上个博客的，由于之前安装的版本号是418.56.这里显示的Driver Version是418.56<br>再次重新启动电脑如果你的电脑分辨率恢复正常就说明我们的驱动显卡安装完成，在这当中有些小伙伴可能会出现循环登录的情况。这一点听大哥说法是–no-opengl-files  –no-nouveau-check  –no-x-check ，这三个参数的原因可能你的只需要加入一个–no-opengl-files ，这一点博主也不是很了解。</p><h1 id="三-安装CUDA"><a href="#三-安装CUDA" class="headerlink" title="三 安装CUDA"></a>三 安装CUDA</h1><p><img src="https://img-blog.csdnimg.cn/20190504140145732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="CUDA与显卡驱动版本对应关系图"><br>去网站下载驱动<br><a href="https://developer.nvidia.com/cuda-release-candidate-download" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-release-candidate-download</a><br>根据自己的系统下载CUDA 这里就不放图了 但是要记住 下载runfile(local)文件<br>下载完后找到下载CUDA文件的位置 右键打开终端 输入：<br>在安装CUDA的过程中会提示，CUDA10.0 设备不可用 在安装那一步 -overrid  我百度查到的结果是编译器不兼容导致的。</p><pre><code class="javascript">sudo chmod +x cuda_10.0.130_410.48_linux.runsudo ./cuda_10.0.130_410.48_linux.run -overrid</code></pre><p>注意上面的数字根据自己下载的版本号更改 </p><pre><code>**在安装CUDA的时候 注意不要安装CUDA所带的驱动 由于我们之前安装了显卡驱动了 所以不需要重复安装**</code></pre><p>然后就是配置环境 输入终端命令</p><pre><code class="javascript">sudo gedit ~/.bashrc</code></pre><p>进入编辑模式将下面两条命令加入文档最后面：下面的序列号也需要根据自己的CUDA版本号更改</p><pre><code class="javascript">export PATH=/usr/local/cuda-10.0/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH</code></pre><p>加入后在终端输入，从而使得环境生效</p><pre><code class="javascript">source ~/.bashrc</code></pre><p>在终端输入，即可得到我们的CUDA信息 10.0.130</p><pre><code class="javascript">nvcc -V</code></pre><p>现实如下 可见我们安装的CUDA版本为10.0.130</p><pre><code class="javascript">maqiushuo@maqiushuo-Aspire-E5-572G:~$ nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2018 NVIDIA CorporationBuilt on Sat_Aug_25_21:08:01_CDT_2018Cuda compilation tools, release 10.0, V10.0.130</code></pre><p>验证<br>打开终端输入</p><pre><code class="javascript">cd /usr/local/cuda/samples/1_Utilities/deviceQuery sudo make./deviceQuery</code></pre><p>得到以下结果，及说名CUDA安装成功<br><img src="https://img-blog.csdnimg.cn/20190521211742747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="CUDA测试截图"></p><h1 id="四-安装cuDNN"><a href="#四-安装cuDNN" class="headerlink" title="四 安装cuDNN"></a>四 安装cuDNN</h1><p>打开网站<br><a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a></p><p>下载自己需要的cuDNN</p><p><img src="https://img-blog.csdnimg.cn/20190504145205682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="cuDNN下载界面"><br>我下载的版本为 10.0    下的   cuDNN library for linux<br>下载完成后输入以下命令<br>首先进入你下载文件的文件夹<br>然后解压文件运行以下代码，注意 解压的文件是你下载的文件。。我这里只是提供个例子，当时下载的到底是什么名字我也忘了，所以下面代码的第一行是解压你下载的安装包.要根据你自己的cudnn版本号更改的</p><pre><code class="javascript">tar -xzvf cudnn-10.0-linux-x64-v7.5.0.56.tgzsudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</code></pre><p>到这里cuDNN也已经配置完成</p><h1 id="五-安装anaconda-以及tensorflow-gpu"><a href="#五-安装anaconda-以及tensorflow-gpu" class="headerlink" title="五 安装anaconda 以及tensorflow-gpu"></a>五 安装anaconda 以及tensorflow-gpu</h1><h2 id="1-安装anaconda"><a href="#1-安装anaconda" class="headerlink" title="1.安装anaconda"></a>1.安装anaconda</h2><pre><code class="javascript">bash Anaconda3-5.2.0-Linux-x86_64.sh</code></pre><h2 id="2-在anaconda当中安装-tensorflow虚拟环境这里将其命名为tensorflow"><a href="#2-在anaconda当中安装-tensorflow虚拟环境这里将其命名为tensorflow" class="headerlink" title="2.在anaconda当中安装 tensorflow虚拟环境这里将其命名为tensorflow"></a>2.在anaconda当中安装 tensorflow虚拟环境这里将其命名为tensorflow</h2><pre><code class="javascript">conda create -n tensorflow pip python=3.6</code></pre><h2 id="3-激活tensorflow-之前安装的虚拟环境"><a href="#3-激活tensorflow-之前安装的虚拟环境" class="headerlink" title="3.激活tensorflow(之前安装的虚拟环境)"></a>3.激活tensorflow(之前安装的虚拟环境)</h2><pre><code class="javascript">source activate tensorflow</code></pre><h2 id="4-安装tensorflow-gpu在tensorflow当中-之前安装的虚拟环境"><a href="#4-安装tensorflow-gpu在tensorflow当中-之前安装的虚拟环境" class="headerlink" title="4.安装tensorflow-gpu在tensorflow当中(之前安装的虚拟环境)"></a>4.安装tensorflow-gpu在tensorflow当中(之前安装的虚拟环境)</h2><p>注意不同版本的tensorflow-gpu 对应的CUDA也是不同的<br><a href="https://www.tensorflow.org/install/source" target="_blank" rel="noopener">https://www.tensorflow.org/install/source</a>  从这个网站查找对应你CUDA版本的gpu，我的电脑不能翻墙只能放一张老图<br><img src="https://img-blog.csdnimg.cn/20190504151111420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="ternsorflow-gpu 与CUDA 对应关系"><br>从以上对应版本号上安装对应版本的tensorflow-gpu</p><pre><code class="javascript">pip install tensorflow-gpu == 1.13.1</code></pre><h2 id="5-验证"><a href="#5-验证" class="headerlink" title="5.验证"></a>5.验证</h2><p><img src="https://img-blog.csdnimg.cn/20190504151306674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE0OTQyNw==,size_16,color_FFFFFF,t_70" alt="验证"></p>]]></content>
      
      
      <categories>
          
          <category> 环境搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow-gpu </tag>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
